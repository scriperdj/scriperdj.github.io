<!DOCTYPE html>
<html lang="en">
  <head>
  <meta charset="UTF-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
  <meta name="viewport" content="width=device-width,initial-scale=1.0,maximum-scale=1" />
  <META NAME="ROBOTS" CONTENT="INDEX, FOLLOW">
  <title>It’s time to ditch Apache Spark and love Dask</title>
  <link rel="shortcut icon" href="favicon.ico">
  <meta name="description" content="After a long time, I couldn’t stop myself from writing this blog. This is not about comparing two of these frameworks but if you are interested in that, Dask...">
  <!-- Google Font-->
  <link href='http://fonts.googleapis.com/css?family=Roboto:400,300italic,300,100italic,100,400italic,500,500italic,700,900,900italic,700italic%7COswald:400,300,700' rel='stylesheet' type='text/css'>
  <!-- Design Style -->
  <link rel="stylesheet" type="text/css" href="/css/style.css" />
  <link rel="stylesheet" type="text/css" href="/css/carousel.css">
  <!-- Icon -->
  <link rel="stylesheet" type="text/css" href="/css/font-awesome.css" />
  <!-- Responsive -->
  <link rel="stylesheet" type="text/css" href="/css/responsive.css" />
  <!-- Pygments -->
  <link rel="stylesheet" type="text/css" href="/css/monokai.css" />
  <script type="text/javascript" src="/js/jquery-2.0.3.min.js"></script>
  <script>
    (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
    (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
    m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
    })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

    ga('create', 'UA-79509088-1', 'auto');
    ga('send', 'pageview');

  </script>
</head>

  <body class="blog">
    <div id="container" class="container">
      <!-- Left Menu / Logo-->
      <aside class="menu" id="menu">
  <div class="logo">
    <!-- Logo image-->
    <img src="/images/logo.png" width="140" height="140" alt=""/>
    <!-- Logo name-->
    <span>Sathish Jayaraman</span>
  </div>
  <!-- Mobile Navigation-->
  <a href="#menu1" class="menu-link"></a>
  <!-- Left Navigation-->
  <nav id="menu1" role="navigation">
    <a href="/index.html?page=about">
      <span class="active" id="link_about">About</span>
    </a>
    <a href="/index.html?page=skills">
      <span id="link_skills">Skills</span>
    </a>
    <a href="/index.html?page=experience">
      <span id="link_experience">Experience</span>
    </a>
    <a href="/index.html?page=education">
      <span id="link_education">Education</span>
    </a>
    <a href="/index.html?page=contact">
      <span id="link_contact">Contact</span>
    </a>
    <a href="/blog">
      <span id="link_blog">Blog</span>
    </a>
  </nav>
  <div class="copyright">
     &copy; Sathish Jayaraman.<br>
     All Rights Reserved.<br><br>
     <!-- <center>Powered by <img src="/images/jekyll.png" width="80" alt=""/></center> -->
  </div>

</aside>

      <div class="blog-main">
        <div class="blog-left">
          <div class="blog-title blog-details-title">
            <h2>It’s time to ditch Apache Spark and love Dask</h2>
            <div class="breadcrumbs"><a href="/index.html?page=about">Home</a>&nbsp;&nbsp;/&nbsp;&nbsp;<a href="/blog">Blog</a>&nbsp;&nbsp;/&nbsp;&nbsp;It’s time to ditch Apache Spark and love Dask</div>
            <span class="post-details ">Saturday &nbsp;/&nbsp; 05 June 2021 &nbsp;/&nbsp; <a href="#">Spark</a></span>
          </div>
          <p>After a long time, I couldn’t stop myself from writing this blog. This is not about comparing two of these frameworks but if you are interested in that, Dask is humble enough to include that in their <a href="https://docs.dask.org/en/latest/spark.html">official documentation</a> as well.  Am just sharing personal opinion from building applications using both of these frameworks.
<img src="/images/posts/spark_dask.jpg" alt="spark_dask" /></p>
<h5 id="spark-is-great-but">Spark is great, but…</h5>
<p>At Quartic.ai, we have built multiple jobs using Apache Spark that does ingress, ETL, score models, etc for different kinds of data which are of both streaming &amp; batch nature. Spark’s rich set of APIs would make your job easy if you have everything as dataframes &amp; RDDs spread across multiple nodes in cluster. But the problem lies in building the required dataframes just so we can make use of the APIs provided by Spark. This is the time to call</p>

<p><img src="/images/posts/avengers.jpg" alt="Dataengineers assemble" /></p>

<p>We have data streaming at high frequency from multiple IoT sensors. Now imagine building pipeline to serve thousands of machine learning models on top of this data using using Apache Spark. Here is a nice <a href="https://databricks.com/blog/2020/05/19/manage-and-scale-machine-learning-models-for-iot-devices.html">blog by Conor Murphy</a> where he explains about training &amp; deploying multiple models at scale. This is great, but in practice we don’t just deploy one model per device. There can be multiple models for one sensor. And there are also instances where prediction from one model is feature to bunch of other models. Generating streaming datasets for this usecase without introducing skewness to your pipelines requires you to carefully choose the partitioning strategy (whether to use device-id, model-id or something else as partition key to kafka topics).</p>

<h5 id="did-it-work-well">Did it work? well…</h5>

<p>After undergoing all trouble of building pipelines that performs cleanups, ETLs, denormalizations on data we realized we can’t scale beyond a limit without scaling the cluster if we don’t want to compromise on batch intervals(which was set to 30sec). And the max no. of models we could deploy in our cluster was also surprisingly small. The max we could serve on a cluster with 24 cores was about 600 models.</p>

<p>Our problem was not just ML models, there are custom code written by our platform users that had to be executed on streaming data which may be used as features to multiple ML models. So we have to implement ways to resolve such dependencies as well.  This is not straight forward in Spark. We had to create different pipelines &amp; loopbacks to do this which wasn’t really efficient if you are already on resource crunch.</p>

<p><img src="/images/posts/influx_pipeline.png" alt="pipeline" /></p>

<h5 id="thinking-small">Thinking small</h5>

<p>It became clear that if we can build a DAG ourselves, there is scope of avoiding some redundant work. Spark builds DAGs before executing jobs, but we couldn’t find any high-level APIs that we could use. We had been using a small python library called <a href="https://github.com/yahoo/graphkit">Graphkit</a> for some application before. So we wanted to give it a try without thinking a lot on scalability. Graphkit turned out to be great for our problem of resolving dependencies. 
 <img src="/images/posts/graphkit.png" alt="graphkit" />
It works for small applications, toy projects/ POCs, scaling this is a challenge.</p>

<h5 id="meet-the-graphkit-on-steroids-dask">Meet the Graphkit on steroids, Dask</h5>

<p>While brainstorming this approach, my teammate recommended Dask. I always thought it was for processing pandas dataframes at scale which is something that Spark is already good at. But never knew of their other APIs. Dask’s <a href="https://docs.dask.org/en/latest/delayed.html">Delayed API</a> is exactly what we wanted. Not only it allowed us to build the required DAG using low level APIs, the graph can be executed in distributed fashion at scale as well.</p>

<p><img src="/images/posts/dask_graph.png" alt="graphkit" /></p>

<p>The API was quite powerful &amp; we were able to quickly build a solution by clubbing Graphkit &amp; Dask to serve thousands on models on the same 24 core cluster that also has the dependencies resolved dynamically. It was so beautiful to see thousands of nodes getting processed in few seconds.</p>

<h5 id="conclusion">Conclusion</h5>

<p>Like I said in beginning, this isn’t an one-o-one comparison. But if you had read the comparison doc, you know which one to pick when. There are situations in a startup company where sometimes we try to get the job done using the tools we know or heard as we have to reach the market faster. Though this involves implementing workarounds, it may not always be a best solution. At Quartic, we are always on the lookout to improve our platform and we are glad how Dask worked out for us.</p>


          <div id="comments" class="comments-main">
            
              <div id="disqus_thread"></div>
              <script>

                /**
                *  RECOMMENDED CONFIGURATION VARIABLES: EDIT AND UNCOMMENT THE SECTION BELOW TO INSERT DYNAMIC VALUES FROM YOUR PLATFORM OR CMS.
                *  LEARN WHY DEFINING THESE VARIABLES IS IMPORTANT: https://disqus.com/admin/universalcode/#configuration-variables*/
                /*
                var disqus_config = function () {
                this.page.url = PAGE_URL;  // Replace PAGE_URL with your page's canonical URL variable
                this.page.identifier = PAGE_IDENTIFIER; // Replace PAGE_IDENTIFIER with your page's unique identifier variable
                };
                */
                (function() { // DON'T EDIT BELOW THIS LINE
                var d = document, s = d.createElement('script');
                s.src = '//sathish-me.disqus.com/embed.js';
                s.setAttribute('data-timestamp', +new Date());
                (d.head || d.body).appendChild(s);
                })();
              </script>
              <noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
              <!-- <div id="fb-root"></div>
              <script>(function(d, s, id) {
                var js, fjs = d.getElementsByTagName(s)[0];
                if (d.getElementById(id)) return;
                js = d.createElement(s); js.id = id;
                js.src = "//connect.facebook.net/en_US/sdk.js#xfbml=1&version=v2.8&appId=612519132273800";
                fjs.parentNode.insertBefore(js, fjs);
              }(document, 'script', 'facebook-jssdk'));</script>
              <div class="fb-comments" data-href="http://sathish.me/spark/2021/06/05/its-time-to-ditch-apache-spark-and-love-dask.html" data-numposts="5"></div> -->
            
          </div>
        </div>
        <!-- <div class="blog-right">

  <div class="sidebar-block">
    <h3>Categories</h3>
    <ul>
      <li><a href="#">Web Design</a><span class="pull-right">48</span></li>
      <li><a href="#">Featured Blog</a><span class="pull-right">66</span></li>
      <li><a href="#">Photography Idea</a><span class="pull-right">32</span></li>
      <li><a href="#">Design Tutorials</a><span class="pull-right">16</span></li>
      <li><a href="#">News and Events</a><span class="pull-right">25</span></li>
      <li><a href="#">Arts and Entertainment</a><span class="pull-right">38</span></li>
    </ul>
  </div>
  <div class="sidebar-block">
    <h3>Tags Cloud</h3>
    <div class="tagcloud"> <a href="javascript:void(0)">Advertisement</a> <a href="javascript:void(0)">Fashion</a> <a href="javascript:void(0)">Forest</a> <a href="javascript:void(0)">Nature</a> <a href="javascript:void(0)">Photo</a> <a href="javascript:void(0)">Portrait</a> <a href="javascript:void(0)">Sea</a> <a href="javascript:void(0)">Sky</a> <a href="javascript:void(0)">Wordpress</a> </div>
  </div>

</div>
 -->
      </div>
    </div>
    <!-- Portfolio Slider-->
<script type="text/javascript" src="/js/carousel.js"></script>
<script type="text/javascript" src="/js/settings-blog.js"></script>
<script>
$(document).ready(function(){
  $('#link_blog').addClass("active")
  $('#link_about').removeClass('active');
});
</script>

  </body>
</html>
